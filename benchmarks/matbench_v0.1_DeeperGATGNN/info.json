{
  "authors": "Sadman Sadeed Omee, Steph-Yves Louis, Nihang Fu, Lai Wei, Sourin Dey, Rongzhi Dong, Qinyang Li, Jianjun Hu",
  "algorithm": "DeeperGATGNN",
  "algorithm_long": "Scalable deeper graph neural networks for high-performance materials property prediction (https://www.cell.com/patterns/pdfExtended/S2666-3899(22)00076-9). We propose a scalable global graph attention neural network model DeeperGATGNN with differentiable group normalization (DGN) and skip connections for high-performance materials property prediction. Our model not only achieved state-of-the art results on benchmark dataset, but also is the most scalable one in terms of graph convolution layers, which allows us to train very deep networks (e.g., >30 layers) without significant performance degradation. Source code link: https://github.com/usccolumbia/deeperGATGNN",
  "bibtex_refs": "@article{omee2022scalable,\n title={Scalable deeper graph neural networks for high-performance materials property prediction},\n author={Omee, Sadman Sadeed and Louis, Steph-Yves and Fu, Nihang and Wei, Lai and Dey, Sourin and Dong, Rongzhi and Li, Qinyang and Hu, Jianjun},\n journal={Patterns},\n year={2022},\n publisher={Elsevier}\n}",
  "notes": "Check your PyTorch and CUDA versions for installing appropriate version of torch-scatter, torch-sparse, torch-cluster, torch-spline-conv, and torch-geometric. Our code can be run on multiple GPUs. If you face any issues, create a new issue in our github repository or email me at omee.sadman@gmail.com",
  "requirements": {"python":  ["torch==1.10.0+cu113", "torch-scatter==2.0.9", "torch-sparse==0.6.13", "torch-spline-conv==1.2.1", "torch-cluster==1.6.0", "torch-geometric==2.0.4", "pymatgen==2023.3.23", "ase==3.22.1", "dscribe==1.2.2", "hyperopt==0.2.5", "joblib==1.2.0", "matplotlib==3.7.1", "numpy==1.21.0", "pickle5==0.0.11", "ray==1.11.0", "scikit-learn==1.2.2", "scipy==1.10.1", "tensorboardX==2.6"]}
}