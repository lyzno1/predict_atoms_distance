{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "minor-joint",
   "metadata": {},
   "source": [
    "# Automatminer v1.0.3.20200727 on Matbench v0.1\n",
    "###### Created April 15, 2021\n",
    "\n",
    "![logo](logo.png)\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "This submission is for Automatminer Express v1.0.3.20200727. Automatminer is a fully-automated, feature-based algorithm for prototyping ML pipelines with AutoML search for hyperparameter optimization. Find the full source code of automatminer at [https://github.com/hackingmaterials/automatminer](https://github.com/hackingmaterials/automatminer).\n",
    "\n",
    "# Benchmark name\n",
    "Matbench v0.1\n",
    "\n",
    "# Package versions\n",
    "```\n",
    "- matbench==0.1.0\n",
    "- automatminer==1.0.3.20200727 # many packages, such as matminer, have specific required versions specified in this version of automatminer\n",
    "```\n",
    "\n",
    "# Algorithm description\n",
    "The Automatminer express model is an abridged version of the full Automatminer pipeline described in [Dunn et al.](https://doi.org/10.1038/s41524-020-00406-3).\n",
    "\n",
    "Automatminer works in 4 distinct steps:\n",
    "- **Autofeaturization**: Sequentially apply many featurizers implemented in matminer (most of which are \"hand crafted\" (meaning a scientist has thought about their physical interpretation and relevance); automatically remove those failing preliminary validity pre-checks and those with high failure rates.\n",
    "- **Data cleaning**: Remove and impute nan samples. Remove erroneous and inf features from autofeaturization.\n",
    "- **Feature reduction**: Intelligently reduce the number of features - for example, removing similar features between distinct featurizers with correlation-based feature reduction, then sequentially applying tree-model-based feature reduction.\n",
    "- **AutoML**: Using TPOT's genetic algorithm-based optimization, evolve different machine learning pipelines based on internal validation scores. This optimization also automatically tunes the hyperparameters of the models. Some of the included models are Random Forest, Gradient Boosted Trees, Logistic Regression, Linear regression (with various regularizations), and Support Vector Machines; a full specification of all the models and hyperparameter grids defined for the preset is available in the automatminer [source code](https://github.com/hackingmaterials/automatminer).\n",
    "\n",
    "![pipe](pipe.png)\n",
    "\n",
    "\n",
    "The primary data store of automatminer is the pandas dataframe.\n",
    "\n",
    "![df](dataframe_pipe.png)\n",
    "\n",
    "The primary working object in automatminer is the MatPipe, which holds comprehensive information about each of the above steps. MatPipes utilize a fit/predict style syntax similar to sklearn's `BaseEstimator`. After being fit, MatPipes can be inspected (detailed internal information for each pipeline) with the `.inspect` method or summarized (more abbreviated internal information) with the `.summarize()` method.\n",
    "\n",
    "\n",
    "# Relevant citations\n",
    "- [Dunn et al.](https://doi.org/10.1038/s41524-020-00406-3)\n",
    "- [Olson et al.](http://doi.acm.org/10.1145/2908812.2908918)\n",
    "- [Ward et al.](https://doi.org/10.1016/j.commatsci.2018.05.018)\n",
    "\n",
    "\n",
    "# Any other relevant info\n",
    "\n",
    "This notebook is best run on many-core machines with a high number of `n_jobs` for parallelization. Intermediate results should be saved such that intermittent failures do not crash the entire benchmark. Walltime requested should approximately be 26hr per task, as the maximum evaluation time for each task is 24 hours of AutoML optimization.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our required classes\n",
    "from matbench import MatbenchBenchmark\n",
    "from automatminer import MatPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-oliver",
   "metadata": {},
   "source": [
    "# Running the actual benchmark\n",
    "\n",
    "Fit a pipeline for each fold of each task. \n",
    "\n",
    "If desired, a `cache_src` can be specified as a powerup argument to `from_preset` such that non-unique features are only computed once, drastically reducing the compute time for large datasets such as `matbench_mp_e_form`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a benchmark\n",
    "mb = MatbenchBenchmark(autoload=False)\n",
    "\n",
    "# Run our benchmark on the dummy models\n",
    "for task in mb.tasks:\n",
    "    task.load()\n",
    "    \n",
    "    for fold in task.folds:\n",
    "        \n",
    "        # Change n_jobs if you are running on a lower-core machine\n",
    "        # To something like 2-4\n",
    "        pipe = MatPipe.from_preset(\"express\", n_jobs=10)\n",
    "        \n",
    "        # Get the training data\n",
    "        train_df = task.get_train_and_val_data(fold, as_type=\"df\")\n",
    "\n",
    "        # Fit the automatminer pipeline automatically\n",
    "        target = task.metadata.target\n",
    "        pipe.fit(train_df, target)\n",
    "        \n",
    "        # Get test data (an array of pymatgen.Structure or string compositions, e.g., \"Fe2O3\")\n",
    "        test_inputs = task.get_test_data(fold, include_target=False, as_type=\"df\")\n",
    "        \n",
    "        # Make predictions on the test data, returning an array of either bool or float, depending on problem\n",
    "        predicted_df = pipe.predict(test_inputs)\n",
    "        predictions = predicted_df[f\"{target} predicted\"].tolist()\n",
    "        params = {\"best_pipeine\": pipe.learner.best_pipeline, \"features\": pipe.learner.features}\n",
    "        \n",
    "        # Record predictions\n",
    "        task.record(fold, predictions, params=params)\n",
    "        \n",
    "        # Save the entire pipeline to file, as a means of checkpointing\n",
    "        pipe.save(f\"{task.dataset_name}-{fold}-pipeline.p\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-concept",
   "metadata": {},
   "source": [
    "# Validate and record pipeline config\n",
    "\n",
    "We should record the pipeline config as future versions of automatminer may have different preset configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatminer.presets import get_preset_config\n",
    "\n",
    "# Make sure our benchmark is valid\n",
    "valid = mb.is_valid\n",
    "print(f\"is valid: {valid}\")\n",
    "\n",
    "# Record the pipe config into benchmark metadata, which is the same for all tasks\n",
    "pipe_config = {\n",
    "    'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'express'},\n",
    "    'cleaner_kwargs': {'feature_na_method': 'drop',\n",
    "                    'max_na_frac': 0.1,\n",
    "                    'na_method_fit': 'mean',\n",
    "                    'na_method_transform': 'mean'},\n",
    "    'learner_kwargs': {'max_eval_time_mins': 20,\n",
    "                    'max_time_mins': 1440,\n",
    "                    'memory': 'auto',\n",
    "                    'n_jobs': 10,\n",
    "                    'population_size': 200},\n",
    "    'learner_name': 'TPOTAdaptor',\n",
    "    'reducer_kwargs': {'reducers': ['corr', 'tree'],\n",
    "                    'tree_importance_percentile': 0.99}\n",
    "}\n",
    "mb.add_metadata(pipe_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-polls",
   "metadata": {},
   "source": [
    "# Save our benchmark to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the valid benchmark to file\n",
    "mb.to_file(\"results.json.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8022b3e932e045c760cb4633b91dd1cb8bc60d104ca9808334cbd1645adbe837"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
